version: "3.9"

####################
#  V O L U M E S   #
####################
volumes:
  pgdata:            # persistent Postgres data
  model-store:       # TorchServe .mar files & snapshots

####################
#  N E T W O R K   #
####################
networks:
  whereisthisplace-network:
    driver: bridge

####################
#   S E R V I C E S #
####################
services:

  # ------------------------------------------- #
  # GPU-enabled backend (TorchServe + FastAPI)  #
  # ------------------------------------------- #
  backend:
    container_name: where-backend-gpu
    image: 726580147864.dkr.ecr.eu-central-1.amazonaws.com/where-backend:latest
    restart: unless-stopped

    ## ENV ##
    env_file: .env
    environment:
      - PYTHONPATH=/app
      - TZ=UTC

    ## STARTUP ##
    command:
      - /bin/bash
      - -c
      - |
        set -e

        # runtime deps missing from the slim Poetry export
        # runtime deps missing from the slim Poetry export
        /home/venv/bin/pip install --no-cache-dir \
          "uvicorn[standard]" fastapi python-multipart psycopg[binary] **asyncpg** requests


        # ---------- TorchServe ----------- #
        ts_cfg="${TORCHSERVE_CONFIG_FILE:-/app/config/config.properties}"
        if [ ! -f "$ts_cfg" ]; then
          echo "WARN  $ts_cfg not found; starting without custom config"
          ts_cfg=""
        fi

        torchserve --start --ncs \
                   --model-store /model-store \
                   --models all \
                   ${ts_cfg:+--ts-config "$ts_cfg"}

        # give TorchServe a head-start
        sleep 30

        # ---------- FastAPI --------------- #
        exec /home/venv/bin/uvicorn api.main:app \
             --host 0.0.0.0 --port 8000 --log-level "${LOG_LEVEL:-info}"

    ## PORTS ##
    ports:
      - "8000:8000"   # FastAPI
      - "8080:8080"   # TorchServe inference
      - "8081:8081"   # TorchServe management
      - "8082:8082"   # TorchServe metrics

    ## GPU ##
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    ## MOUNTS ##
    volumes:
      - model-store:/model-store
      - ./config:/app/config:ro
      - ./ml:/app/ml:ro
      - ./scripts:/app/scripts:ro
      - ./models:/app/models:ro
      - ./logs:/app/logs

    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - whereisthisplace-network

  # ------------------------ #
  # Postgres 16 + pgvector   #
  # ------------------------ #
  postgres:
    container_name: where-postgres
    image: pgvector/pgvector:pg16
    restart: unless-stopped
    environment:
      POSTGRES_DB:       ${POSTGRES_DB:-where}
      POSTGRES_USER:     ${POSTGRES_USER:-where}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-where}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - whereisthisplace-network
