version: "3.9"

####################
#  V O L U M E S   #
####################
volumes:
  pgdata:            # persistent Postgres data
  model-store:       # TorchServe .mar files and snapshots

####################
#  N E T W O R K   #
####################
networks:
  whereisthisplace-network:
    driver: bridge

####################
#   S E R V I C E S #
####################
services:

  # ------------------------------------------- #
  # GPU-enabled backend (TorchServe + FastAPI)  #
  # ------------------------------------------- #
  backend:
    container_name: where-backend-gpu
    image: 726580147864.dkr.ecr.eu-central-1.amazonaws.com/where-backend:latest
    restart: unless-stopped

    # -------- ENV -------- #
    env_file: .env          # holds MAPBOX_TOKEN, DB creds, LOG_LEVEL, etc.
    environment:
      - PYTHONPATH=/app
      - TZ=UTC

    # -------- COMMAND ------ #
    command: ["/bin/bash", "-c", |
      set -e

      # Install small runtime deps that Poetry leaves out
      /home/venv/bin/pip install --no-cache-dir \
          "uvicorn[standard]" fastapi python-multipart psycopg[binary] requests

      # -------- TorchServe ---------- #
      ts_cfg="${TORCHSERVE_CONFIG_FILE:-/app/config/config.properties}"
      test -f "$ts_cfg" || { echo "WARN  $ts_cfg not found, starting without custom config"; ts_cfg=""; }

      torchserve --start --ncs \
                 --model-store /model-store \
                 --models all \
                 ${ts_cfg:+--ts-config "$ts_cfg"}

      # give TorchServe a head-start
      sleep 25

      # -------- FastAPI ------------- #
      exec /home/venv/bin/uvicorn api.main:app \
           --host 0.0.0.0 --port 8000 --log-level "${LOG_LEVEL:-info}"
    ]

    # -------- PORTS -------- #
    ports:
      - "8000:8000"   # FastAPI
      - "8080:8080"   # TorchServe inference
      - "8081:8081"   # TorchServe management
      - "8082:8082"   # TorchServe metrics

    # -------- GPU --------- #
    deploy:                                 # picked up by docker-compose as well
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]          # enable every visible GPU  :contentReference[oaicite:0]{index=0}

    volumes:
      - model-store:/model-store
      - ./config:/app/config:ro            # custom TorchServe & app settings

    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - whereisthisplace-network

  # ------------------------ #
  # Lightweight Postgres 16  #
  # ------------------------ #
  postgres:
    container_name: where-postgres
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_DB:     ${POSTGRES_DB:-where}
      POSTGRES_USER:   ${POSTGRES_USER:-where}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-where}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - whereisthisplace-network
