version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: where-postgres
    environment:
      # These can also be moved to .env if you prefer consistency
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: whereisthisplace
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql # Ensure this init script is suitable
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - whereisthisplace-network

  backend:
    image: 726580147864.dkr.ecr.eu-central-1.amazonaws.com/where-backend:latest
    container_name: where-backend-gpu
    runtime: nvidia
    # Variables like PYTHONPATH, TORCHSERVE_CONFIG_FILE, LOG_LEVEL, MAPBOX_TOKEN
    # will be sourced from the .env file and made available to the container's environment.
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      PYTHONUNBUFFERED: 1
      # If DATABASE_URL and TORCHSERVE_URL are in your .env, you can remove them from here.
      # Otherwise, these provide defaults if not in .env (Compose substitutes ${...} from .env first).
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:postgres@postgres:5432/whereisthisplace}
      TORCHSERVE_URL: ${TORCHSERVE_URL:-http://localhost:8080}
    volumes:
      # - ./api:/app/api:rw  # REMOVED: API code now comes from the Docker image.
      - ./ml:/app/ml:rw      # Mount local ./ml to /app/ml; remove if ML files are also in image and not to be overwritten.
      - ./scripts:/app/scripts:rw # Mount local ./scripts; remove if scripts are also in image and not to be overwritten.
      - ./logs:/app/logs:rw      # Mount host logs directory to persist container logs.
      # - ./models:/model-store:ro # Uncomment if you want to mount models from host instead of using those in the image.
      - ./config:/app/config:ro   # CRITICAL: Mounts host's ./config directory to /app/config for config.properties.
    ports:
      - "8000:8000" # FastAPI
      - "8080:8080" # TorchServe inference
      - "8081:8081" # TorchServe management
      - "8082:8082" # TorchServe metrics
    depends_on:
      postgres:
        condition: service_healthy
    entrypoint: /bin/bash
    command:
      - "-c"
      - |
        set -e # Exit immediately if a command exits with a non-zero status.
        echo '=== Backend Service Starting (Script Version FINAL .env V3) ==='
        echo "Running as user: $(whoami)"
        
        # These variables are now expected to be correctly populated in the shell's environment from the .env file.
        echo "PYTHONPATH from environment: '$PYTHONPATH'"
        echo "TORCHSERVE_CONFIG_FILE from environment (initial read): '$TORCHSERVE_CONFIG_FILE'"
        echo "LOG_LEVEL from environment: '$LOG_LEVEL'"
        # For security, avoid printing sensitive tokens: echo "MAPBOX_TOKEN is set (value not shown)"

        echo 'Installing/Verifying required Python packages in /home/venv/...'
        # This assumes these might not be in the image's venv or you want to ensure specific versions.
        /home/venv/bin/pip3 install --no-cache-dir requests fastapi uvicorn psycopg2-binary pgvector python-multipart
        
        echo 'Starting TorchServe...'
        
        # Clean and verify TORCHSERVE_CONFIG_FILE value from .env
        # Use a distinct script-local variable name to avoid conflicts with Docker Compose's interpretation of certain names.
        config_file_from_env_cleaned=$(echo "$TORCHSERVE_CONFIG_FILE" | tr -d '\r' | xargs) # Cleans \r and trims whitespace
        echo "DEBUG: Cleaned TORCHSERVE_CONFIG_FILE value (in 'config_file_from_env_cleaned') is: -->'$config_file_from_env_cleaned'<--"

        # This variable will hold the path TorchServe actually uses
        ts_config_to_use=""

        # Scenario 1: The cleaned environment variable points to an existing file
        if [ -n "$config_file_from_env_cleaned" ] && [ -f "$config_file_from_env_cleaned" ]; then
            echo "INFO: Valid config file found from .env variable: '$config_file_from_env_cleaned'"
            ts_config_to_use="$config_file_from_env_cleaned"
        else
            # Log why the environment variable wasn't used
            if [ -z "$config_file_from_env_cleaned" ]; then
                echo "WARNING: TORCHSERVE_CONFIG_FILE from .env was empty or became empty after cleaning."
            else # It was not empty, so the file must not exist at that path
                echo "WARNING: TORCHSERVE_CONFIG_FILE from .env was '$config_file_from_env_cleaned', but this file was not found."
            fi
            
            # Scenario 2: Fallback to the hardcoded default path (which comes from the host mount)
            default_ts_config_path="/app/config/config.properties"
            echo "INFO: Attempting to use fallback default config path: '$default_ts_config_path'"
            if [ -f "$default_ts_config_path" ]; then
                echo "INFO: Default config file '$default_ts_config_path' found and will be used."
                ts_config_to_use="$default_ts_config_path"
            else
                echo "ERROR: Default config file '$default_ts_config_path' also not found. This path relies on the host's ./config/config.properties being correctly mounted."
            fi
        fi

        # Now, start TorchServe based on whether we found a valid config file
        if [ -n "$ts_config_to_use" ]; then
            echo "TorchServe will be started with --ts-config '$ts_config_to_use'"
            torchserve --start --ncs --model-store /model-store --models all --ts-config "$ts_config_to_use"
        else
            echo "ERROR: No valid TorchServe config file could be determined. Starting TorchServe without --ts-config (will use defaults and may not work as expected)."
            torchserve --start --ncs --model-store /model-store --models all
        fi
        
        echo "Listing contents of /model-store (should be from image unless ./models volume mount is active):"
        ls -l /model-store/

        echo 'Waiting for TorchServe to initialize (e.g., 30 seconds)...'
        sleep 30 
        
        echo 'Checking TorchServe management API (if curl is available)...'
        if command -v curl &> /dev/null; then
            echo "Querying http://localhost:8081/models..."
            curl -vs http://localhost:8081/models || echo "INFO: curl to /models failed. TorchServe management API might not be ready or endpoint differs."
            echo "Querying http://localhost:8081/ping..."
            curl -vs http://localhost:8081/ping || echo "INFO: curl to /ping failed. (This is often a 404 by default for /ping on management if not specifically configured)."
        else
            echo "INFO: curl command not found. Skipping API checks in startup script. Consider installing curl in the Docker image for these checks."
        fi

        echo 'Starting FastAPI application (uvicorn)...'
        cd /app # Ensure current working directory is /app
        echo "Current Directory for Uvicorn: $(pwd)"
        echo "PYTHONPATH for Uvicorn: '$PYTHONPATH'" # Should be /app from .env
        echo "LOG_LEVEL for Uvicorn: '$LOG_LEVEL'" # Should be 'info' (lowercase) from .env
        
        # Uvicorn will use LOG_LEVEL from the environment. Ensure it's lowercase 'info', 'debug', etc., in .env
        /home/venv/bin/python3 -m uvicorn api.main:app --host 0.0.0.0 --port 8000 --log-level "$LOG_LEVEL"

  adminer:
    image: adminer
    container_name: where-adminer
    ports:
      - "8090:8080"
    depends_on:
      - postgres
    networks:
      - whereisthisplace-network
    environment:
      - ADMINER_DEFAULT_SERVER=postgres

volumes:
  postgres_data:
    driver: local

networks:
  whereisthisplace-network:
    driver: bridge