# WhereIsThisPlace GPU backend image
FROM pytorch/torchserve:0.10.0-gpu

# Install Poetry and project dependencies
USER root
WORKDIR /app

# Copy application code
COPY ../../api /app/api
COPY ../../ml  /app/ml

# Copy Poetry files
COPY ../../api/pyproject.toml /app/api/
COPY ../../api/poetry.lock /app/api/

RUN pip install --no-cache-dir poetry==1.8.3 && \
    poetry config virtualenvs.create false && \
    poetry --directory /app/api install --no-interaction --no-ansi --only main --no-root

# Bundle models inside the image
COPY ../../models/where.mar /model-store/
COPY ../../models/mapillary_WPCA128.pth.tar /model-store/

# Provide fallback TorchServe configuration
RUN mkdir -p /app/config && \
    echo "inference_address=http://0.0.0.0:8080" > /app/config/config.properties && \
    echo "management_address=http://0.0.0.0:8081" >> /app/config/config.properties && \
    echo "metrics_address=http://0.0.0.0:8082" >> /app/config/config.properties && \
    echo "model_store=/model-store" >> /app/config/config.properties && \
    echo "load_models=where.mar" >> /app/config/config.properties

USER model-server
CMD ["torchserve", "--start", "--model-store", "/model-store", "--ncs", "--ts-config", "/app/config/config.properties"]
