# ------------------------------------------------------------
# WhereIsThisPlace – GPU backend image (TorchServe + FastAPI + FAISS-GPU)
# ------------------------------------------------------------
FROM pytorch/torchserve:0.10.0-gpu

# Build-time variables & environment
ARG FAISS_VER=1.7.4
ENV DEBIAN_FRONTEND=noninteractive \
    FAISS_ENABLE_GPU=ON \
    FAISS_OPT_LEVEL=avx2 \
    CMAKE_CUDA_ARCHITECTURES="75" \
    PATH="/usr/local/cuda/bin:${PATH}" \
    LD_LIBRARY_PATH="/usr/local/cuda/lib64:${LD_LIBRARY_PATH}"

# Explicitly switch to root user for system package installation
USER root

# 1. System dependencies for FAISS build and CMake installation
RUN apt-get update && apt-get install -y --no-install-recommends \
      build-essential ninja-build git swig \
      libopenblas-dev ca-certificates wget \
      software-properties-common gnupg lsb-release && \
    rm -rf /var/lib/apt/lists/*

# 2. Install newer CMake (required for FAISS v1.7.4 - needs CMake 3.23.1+)
RUN wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | \
    gpg --dearmor - | \
    tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null && \
    echo "deb https://apt.kitware.com/ubuntu/ $(lsb_release -cs) main" | \
    tee /etc/apt/sources.list.d/kitware.list >/dev/null && \
    apt-get update && \
    apt-get install -y cmake && \
    echo "Installed CMake version:" && cmake --version && \
    rm -rf /var/lib/apt/lists/*

# 3. Copy application source
WORKDIR /app
COPY api/ ./api
COPY ml/  ./ml
# If you have a 'models' directory in the build context for where-v1.mar, copy it too
COPY models/ /app/models

# 4. Install Python dependencies via Poetry
RUN pip install --no-cache-dir poetry==1.8.3 && \
    # Export poetry dependencies to requirements.txt and install them
    poetry --directory ./api export --without-hashes --only main -f requirements.txt | \
    pip install --no-cache-dir -r /dev/stdin && \
    # Install additional required packages
    pip install --no-cache-dir uvicorn[standard] pybind11

# 5. Build & install FAISS-GPU from source (≈ 7-10 min)
# This step requires the newer CMake installed in step 2
RUN echo "Building FAISS with CMake version:" && cmake --version && \
    git clone --depth 1 --branch v${FAISS_VER} https://github.com/facebookresearch/faiss.git && \
    cmake -G Ninja -S faiss -B faiss/build \
        -DFAISS_ENABLE_GPU=${FAISS_ENABLE_GPU} \
        -DFAISS_ENABLE_PYTHON=ON \
        -DFAISS_OPT_LEVEL=${FAISS_OPT_LEVEL} \
        -DCMAKE_CUDA_ARCHITECTURES=${CMAKE_CUDA_ARCHITECTURES} \
        -DCUDAToolkit_ROOT=/usr/local/cuda && \
    cmake --build faiss/build --target swigfaiss_avx2 faiss && \
    cmake --install faiss/build && \
    pip install faiss/build/faiss/python && \
    rm -rf faiss && \
    echo "FAISS installation completed successfully"

# 6. Prepare model store directory
RUN mkdir -p /model-store && \
    if [ -f /app/models/where-v1.mar ]; then \
        cp /app/models/where-v1.mar /model-store/ && \
        echo "Model artifact copied to /model-store/"; \
    else \
        echo "No model artifact found at /app/models/where-v1.mar"; \
    fi

# 7. Setup entrypoint script
COPY api/docker/start.sh /start.sh
RUN chmod +x /start.sh

# 8. Expose ports (8080 for TorchServe, 8081 for FastAPI)
EXPOSE 8080 8081

# 9. Set default command
CMD ["/start.sh"]

# Note: If the pytorch/torchserve base image requires a specific user,
# uncomment the following line:
# USER torchserve
