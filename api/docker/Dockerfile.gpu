# WhereIsThisPlace GPU backend image
FROM pytorch/torchserve:0.10.0-gpu

# Install Poetry and project dependencies
USER root
WORKDIR /app

# Copy Poetry files first for caching
COPY ../../api/pyproject.toml ./api/
COPY ../../api/poetry.lock ./api/

RUN pip install --no-cache-dir poetry && \
    poetry config virtualenvs.create false && \
    poetry --directory /app/api install --without dev --no-interaction

# Copy application code
COPY ../../api /app/api
COPY ../../ml  /app/ml

# Bundle models inside the image
COPY ../../models/where.mar /model-store/
COPY ../../models/mapillary_WPCA128.pth.tar /model-store/

# Provide fallback TorchServe configuration
RUN mkdir -p /app/config && \
    echo "inference_address=http://0.0.0.0:8080" > /app/config/config.properties && \
    echo "management_address=http://0.0.0.0:8081" >> /app/config/config.properties && \
    echo "metrics_address=http://0.0.0.0:8082" >> /app/config/config.properties && \
    echo "model_store=/model-store" >> /app/config/config.properties && \
    echo "load_models=where.mar" >> /app/config/config.properties

USER model-server
CMD ["/app/api/docker/start.sh"]
